{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Schemalog\n",
       "schemaFromClass = StructType(StructField(UID,StringType,true), StructField(timestamp,StringType,true), StructField(URL,StringType,true))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "parser: (url: String)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(UID,StringType,true), StructField(timestamp,StringType,true), StructField(URL,StringType,true))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys.process._\n",
    "import java.net.URLDecoder\n",
    "import scala.util.{Try, Success, Failure}\n",
    "import org.apache.spark.sql.functions.udf\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.catalyst.ScalaReflection\n",
    "case class Schemalog(\n",
    "    UID: String,\n",
    "    timestamp: String,\n",
    "    URL: String\n",
    ")\n",
    "val schemaFromClass = ScalaReflection.schemaFor[Schemalog].dataType.asInstanceOf[StructType]\n",
    "def parser(url: String) = {\n",
    "    Try {new java.net.URL(URLDecoder.decode(url, \"UTF-8\"))}.toOption\n",
    "      match {\n",
    "        case Some(_) => new java.net.URL(URLDecoder.decode(url, \"UTF-8\")).getHost\n",
    "        case _ => \"unable_to_parse\"\n",
    "      }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "autom = [autousers: array<string>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[autousers: array<string>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val autom = spark.read.option(\"header\", \"true\").option(\"multiline\", \"true\").option(\"encoding\", \"UTF-8\").json(\"/labs/laba02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autom_explode = [autousers: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[autousers: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val autom_explode = autom.select(org.apache.spark.sql.functions.explode($\"autousers\").alias(\"autousers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "csvOptions = Map(encoding -> UTF-8, inferSchema -> false, sep -> \"\t\", charset -> UTF8, header -> true)\n",
       "log = [UID: string, timestamp: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[UID: string, timestamp: string ... 1 more field]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val csvOptions = Map(\"header\" -> \"true\", \"inferSchema\" -> \"false\", \"sep\" -> \"\\t\", \"encoding\" -> \"UTF-8\", \"charset\" -> \"UTF8\" )\n",
    "val log = spark.read.options(csvOptions).schema(schemaFromClass).csv(\"/labs/laba02/logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_auto = [UID: string, timestamp: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[UID: string, timestamp: string ... 2 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val log_auto=log.join(autom_explode, log(\"UID\") ===  autom_explode(\"autousers\"), \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isAlienNameUDF2 = UserDefinedFunction(<function1>,StringType,Some(List(StringType)))\n",
       "df5 = [UID: string, timestamp: string ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[UID: string, timestamp: string ... 3 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val isAlienNameUDF2 = udf(parser _)\n",
    "val df5 = log_auto.filter(col(\"URL\").like(\"http%\") and col(\"URL\").isNotNull and !col(\"URL\").like(\"\")).withColumn(\"df5\", \n",
    "isAlienNameUDF2(col(\"URL\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isAlienNameUDF2 = UserDefinedFunction(<function1>,StringType,Some(List(StringType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,StringType,Some(List(StringType)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.udf\n",
    "\n",
    "val isAlienNameUDF2 = udf(parser _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avto-russia.ru"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser(\"http%3A%2F%2Favto-russia.ru%2Fautos%2F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df5 = [UID: string, timestamp: string ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[UID: string, timestamp: string ... 3 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df5 = log_auto.filter(col(\"URL\").like(\"http%\") and col(\"URL\").isNotNull and !col(\"URL\").like(\"\")).withColumn(\"df5\", \n",
    "isAlienNameUDF2(col(\"URL\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_auto_fil_2 = [UID: string, timestamp: string ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[UID: string, timestamp: string ... 4 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val log_auto_fil_2 = df5.filter(col(\"df5\").like(\"www.%\")).withColumn(\"ur\", regexp_replace($\"df5\", \"www.\", \"\")).union(df5.filter(!col(\"df5\").like(\"www.%\")).withColumn(\"ur\", col(\"df5\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_auto_flag = [UID: string, timestamp: string ... 5 more fields]\n",
       "cnt = 6570395\n",
       "cnt_1 = 313498\n",
       "log_auto_1 = [ur: string, gr_1: bigint ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ur: string, gr_1: bigint ... 1 more field]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val log_auto_flag = log_auto_fil_2.withColumn(\"flag\", when(col(\"autousers\").isNull , 0).otherwise(1))\n",
    "val cnt = log_auto_flag.count()\n",
    "val cnt_1 = log_auto_flag.filter(col(\"flag\") === 1).count()\n",
    "val log_auto_1 = log_auto_flag.groupBy(\"ur\").agg(sum(\"flag\").alias(\"gr_1\"), count(\"flag\").alias(\"gr_all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_auto_rel = [ur: string, gr_1: bigint ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ur: string, gr_1: bigint ... 2 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val log_auto_rel = log_auto_1.withColumn(\"relevance\", format_number((col(\"gr_1\")/lit(cnt))*(col(\"gr_1\")/lit(cnt))/((col(\"gr_all\")/lit(cnt)) * (lit(cnt_1)/lit(cnt))), 15) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_auto_rel.orderBy(col(\"relevance\").desc, col(\"ur\") ).select($\"ur\",$\"relevance\").limit(200).repartition(1).write.mode(\"overwrite\").option(\"header\",false).option(\"encoding\", \"UTF-8\").option(\"sep\",\"\\t\").csv(\"laba02_5_domains.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"hdfs dfs -get laba02_5_domains.txt\"\"\".!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
